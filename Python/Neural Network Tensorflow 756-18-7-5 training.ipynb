{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import pandas as pd\n",
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data \n",
    "path = 'x:/Steering/Recordings/Processed/'\n",
    "data1,_ = sf.read(path + 'ERB=2_MF_01.wav')\n",
    "data2,_ = sf.read(path + 'ERB=2_MF_02.wav')\n",
    "data3,_ = sf.read(path + 'ERB=2_MF_03.wav')\n",
    "\n",
    "classes = pd.read_csv(path + 'Classes_2_MF.csv')\n",
    "\n",
    "data = np.hstack([data1, data2, data3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(970584, 756)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:len(data)-1,:data.shape[1]] #775361\n",
    "Y = classes.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((970583, 756), (970583,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do one-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_encoded_train = trainY.reshape(len(trainY), 1)\n",
    "onehot_encoded_train = enc.fit_transform(integer_encoded_train)\n",
    "\n",
    "integer_encoded_test = testY.reshape(len(testY), 1)\n",
    "onehot_encoded_test = enc.fit_transform(integer_encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoded_train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC removal \n",
    "trainX -= (np.mean(trainX, axis=0) + 1e-8)\n",
    "testX -= (np.mean(testX, axis=0) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((776466, 756), (776466, 5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape, onehot_encoded_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.add(keras.layers.Dense(\n",
    "  units = 18,\n",
    "  input_dim = trainX.shape[1],   \n",
    "  activation = 'tanh'\n",
    "))\n",
    "\n",
    "clf.add (keras.layers.Dense(\n",
    "    units = 7,\n",
    "    input_dim = 18,\n",
    "    activation = 'tanh'\n",
    "))\n",
    "\n",
    "clf.add(keras.layers.Dense(\n",
    "    units = onehot_encoded_train.shape[1],\n",
    "    input_dim = 7,\n",
    "    activation = 'softmax'\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoded_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(loss='mean_squared_error',\n",
    "    optimizer='Adam',\n",
    "           metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 698819 samples, validate on 77647 samples\n",
      "Epoch 1/20\n",
      "698819/698819 [==============================] - 18s 26us/step - loss: 0.0478 - categorical_accuracy: 0.8408 - val_loss: 0.0246 - val_categorical_accuracy: 0.9192\n",
      "Epoch 2/20\n",
      "698819/698819 [==============================] - 15s 22us/step - loss: 0.0179 - categorical_accuracy: 0.9455 - val_loss: 0.0131 - val_categorical_accuracy: 0.9652\n",
      "Epoch 3/20\n",
      "698819/698819 [==============================] - 13s 19us/step - loss: 0.0108 - categorical_accuracy: 0.9679 - val_loss: 0.0145 - val_categorical_accuracy: 0.9531\n",
      "Epoch 4/20\n",
      "698819/698819 [==============================] - 14s 20us/step - loss: 0.0085 - categorical_accuracy: 0.9745 - val_loss: 0.0069 - val_categorical_accuracy: 0.9806\n",
      "Epoch 5/20\n",
      "698819/698819 [==============================] - 14s 20us/step - loss: 0.0076 - categorical_accuracy: 0.9766 - val_loss: 0.0072 - val_categorical_accuracy: 0.9796\n",
      "Epoch 6/20\n",
      "698819/698819 [==============================] - 20s 28us/step - loss: 0.0071 - categorical_accuracy: 0.9780 - val_loss: 0.0173 - val_categorical_accuracy: 0.9350\n",
      "Epoch 7/20\n",
      "698819/698819 [==============================] - 14s 20us/step - loss: 0.0068 - categorical_accuracy: 0.9788 - val_loss: 0.0073 - val_categorical_accuracy: 0.9752\n",
      "Epoch 8/20\n",
      "698819/698819 [==============================] - 14s 20us/step - loss: 0.0065 - categorical_accuracy: 0.9797 - val_loss: 0.0077 - val_categorical_accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "698819/698819 [==============================] - 13s 18us/step - loss: 0.0063 - categorical_accuracy: 0.9803 - val_loss: 0.0075 - val_categorical_accuracy: 0.9753\n",
      "Epoch 10/20\n",
      "698819/698819 [==============================] - 14s 20us/step - loss: 0.0060 - categorical_accuracy: 0.9809 - val_loss: 0.0055 - val_categorical_accuracy: 0.9838\n",
      "Epoch 11/20\n",
      "698819/698819 [==============================] - 16s 23us/step - loss: 0.0059 - categorical_accuracy: 0.9812 - val_loss: 0.0055 - val_categorical_accuracy: 0.9820\n",
      "Epoch 12/20\n",
      "698819/698819 [==============================] - 14s 20us/step - loss: 0.0058 - categorical_accuracy: 0.9818 - val_loss: 0.0052 - val_categorical_accuracy: 0.9836\n",
      "Epoch 13/20\n",
      "698819/698819 [==============================] - 14s 20us/step - loss: 0.0056 - categorical_accuracy: 0.9822 - val_loss: 0.0059 - val_categorical_accuracy: 0.9824\n",
      "Epoch 14/20\n",
      "698819/698819 [==============================] - 14s 20us/step - loss: 0.0056 - categorical_accuracy: 0.9824 - val_loss: 0.0056 - val_categorical_accuracy: 0.9815\n",
      "Epoch 15/20\n",
      "698819/698819 [==============================] - 13s 19us/step - loss: 0.0054 - categorical_accuracy: 0.9829 - val_loss: 0.0050 - val_categorical_accuracy: 0.9853\n",
      "Epoch 16/20\n",
      "698819/698819 [==============================] - 14s 20us/step - loss: 0.0054 - categorical_accuracy: 0.9830 - val_loss: 0.0052 - val_categorical_accuracy: 0.9844\n",
      "Epoch 17/20\n",
      "698819/698819 [==============================] - 13s 19us/step - loss: 0.0052 - categorical_accuracy: 0.9834 - val_loss: 0.0048 - val_categorical_accuracy: 0.9856\n",
      "Epoch 18/20\n",
      "698819/698819 [==============================] - 14s 19us/step - loss: 0.0051 - categorical_accuracy: 0.9838 - val_loss: 0.0045 - val_categorical_accuracy: 0.9864\n",
      "Epoch 19/20\n",
      "698819/698819 [==============================] - 14s 20us/step - loss: 0.0052 - categorical_accuracy: 0.9836 - val_loss: 0.0046 - val_categorical_accuracy: 0.9856\n",
      "Epoch 20/20\n",
      "698819/698819 [==============================] - 14s 20us/step - loss: 0.0050 - categorical_accuracy: 0.9842 - val_loss: 0.0063 - val_categorical_accuracy: 0.9796\n"
     ]
    }
   ],
   "source": [
    "history = clf.fit(trainX,onehot_encoded_train,\n",
    "                 batch_size = 64, epochs = 20,\n",
    "                 verbose = 1,\n",
    "                 validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 5, 1, 5, 2, 4, 4, 2, 4, 4, 3, 2, 3, 1, 3, 3, 2, 4, 3, 4, 2, 4,\n",
       "        4, 2, 5, 5, 4, 5, 2, 2, 5, 4, 4, 1, 5, 4, 2, 2, 5, 2, 4, 4, 5, 3,\n",
       "        1, 3, 5, 5, 3, 2, 2, 5, 1, 5, 5, 4, 5, 4, 4, 2, 2, 2, 1, 4, 2, 1,\n",
       "        2, 2, 1, 4, 2, 1, 4, 2, 1, 5, 3, 4, 5, 4, 3, 5, 2, 5, 2, 2, 2, 2,\n",
       "        5, 5, 5, 4, 4, 2, 4, 5, 2, 1, 1], dtype=int64),\n",
       " array([2, 2, 5, 1, 5, 2, 4, 4, 2, 4, 4, 3, 2, 3, 1, 3, 3, 2, 4, 3, 4, 2,\n",
       "        4, 4, 2, 5, 5, 4, 5, 2, 4, 5, 4, 4, 1, 5, 4, 2, 2, 5, 2, 4, 4, 5,\n",
       "        3, 1, 3, 5, 5, 3, 2, 4, 5, 1, 5, 5, 4, 5, 4, 4, 2, 2, 2, 1, 4, 2,\n",
       "        1, 2, 2, 1, 4, 2, 1, 4, 2, 1, 5, 3, 4, 5, 4, 3, 5, 2, 5, 4, 2, 2,\n",
       "        2, 4, 5, 5, 4, 4, 2, 4, 5, 2, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_classes(testX[1:100,:]) + 1,testY[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model \n",
    "# save model and weights\n",
    "clf_json = clf.to_json()\n",
    "with open(\"NN_756-18-7-5.json\", \"w\") as json_file:\n",
    "    json_file.write(clf_json)\n",
    "    \n",
    "clf.save_weights(\"NN_756-18-7-5_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('TestX_NN_756-18-7-5',testX), np.save('TestY_NN_756-18-7-5',testY),\n",
    "np.save('OneHot_testY_756-18-7-5',onehot_encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194117/194117 [==============================] - 3s 14us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005279907120534479, 0.9826702452644539]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(testX,onehot_encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
