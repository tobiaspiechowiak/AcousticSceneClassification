{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data \n",
    "path = 'x:/Steering/Recordings/Processed/'\n",
    "data, fs = sf.read(path + 'ERB=2_uni_OwnVoice.wav')\n",
    "classes = pd.read_csv(path + 'Classes_2_uni_OwnVoice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:len(data)-1,:data.shape[1]] \n",
    "Y = classes.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366756, 366756)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y),len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do one-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_encoded_train = trainY.reshape(len(trainY), 1)\n",
    "onehot_encoded_train = enc.fit_transform(integer_encoded_train)\n",
    "\n",
    "integer_encoded_test = testY.reshape(len(testY), 1)\n",
    "onehot_encoded_test = enc.fit_transform(integer_encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC removal \n",
    "trainX -= (np.mean(trainX, axis=0) + 1e-8)\n",
    "testX -= (np.mean(testX, axis=0) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.add(keras.layers.Dense(\n",
    "  units = 20,\n",
    "  input_dim = trainX.shape[1],   \n",
    "  activation = 'tanh'\n",
    "))\n",
    "\n",
    "clf.add(keras.layers.Dense(\n",
    "    units = onehot_encoded_train.shape[1],\n",
    "    input_dim = 20,\n",
    "    activation = 'softmax'\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 36)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoded_train.shape[1],trainX.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(loss='mean_squared_error',\n",
    "    optimizer='Adam',\n",
    "           metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 264063 samples, validate on 29341 samples\n",
      "Epoch 1/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1696 - categorical_accuracy: 0.3825 - val_loss: 0.1695 - val_categorical_accuracy: 0.3859\n",
      "Epoch 2/250\n",
      "264063/264063 [==============================] - 2s 7us/step - loss: 0.1694 - categorical_accuracy: 0.3829 - val_loss: 0.1694 - val_categorical_accuracy: 0.3832\n",
      "Epoch 3/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1692 - categorical_accuracy: 0.3842 - val_loss: 0.1692 - val_categorical_accuracy: 0.3835\n",
      "Epoch 4/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1690 - categorical_accuracy: 0.3859 - val_loss: 0.1691 - val_categorical_accuracy: 0.3943\n",
      "Epoch 5/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1688 - categorical_accuracy: 0.3871 - val_loss: 0.1688 - val_categorical_accuracy: 0.3889\n",
      "Epoch 6/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1686 - categorical_accuracy: 0.3884 - val_loss: 0.1686 - val_categorical_accuracy: 0.3903\n",
      "Epoch 7/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1684 - categorical_accuracy: 0.3896 - val_loss: 0.1684 - val_categorical_accuracy: 0.3915\n",
      "Epoch 8/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1682 - categorical_accuracy: 0.3898 - val_loss: 0.1683 - val_categorical_accuracy: 0.4018\n",
      "Epoch 9/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1680 - categorical_accuracy: 0.3923 - val_loss: 0.1680 - val_categorical_accuracy: 0.3935\n",
      "Epoch 10/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1677 - categorical_accuracy: 0.3935 - val_loss: 0.1678 - val_categorical_accuracy: 0.3913\n",
      "Epoch 11/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1675 - categorical_accuracy: 0.3938 - val_loss: 0.1676 - val_categorical_accuracy: 0.3925\n",
      "Epoch 12/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1673 - categorical_accuracy: 0.3944 - val_loss: 0.1674 - val_categorical_accuracy: 0.3943\n",
      "Epoch 13/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1671 - categorical_accuracy: 0.3968 - val_loss: 0.1671 - val_categorical_accuracy: 0.3984\n",
      "Epoch 14/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1668 - categorical_accuracy: 0.3979 - val_loss: 0.1670 - val_categorical_accuracy: 0.4163\n",
      "Epoch 15/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1666 - categorical_accuracy: 0.3983 - val_loss: 0.1667 - val_categorical_accuracy: 0.4035\n",
      "Epoch 16/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1664 - categorical_accuracy: 0.3998 - val_loss: 0.1665 - val_categorical_accuracy: 0.3980\n",
      "Epoch 17/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1662 - categorical_accuracy: 0.4004 - val_loss: 0.1663 - val_categorical_accuracy: 0.3958\n",
      "Epoch 18/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1659 - categorical_accuracy: 0.4021 - val_loss: 0.1660 - val_categorical_accuracy: 0.3999\n",
      "Epoch 19/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1657 - categorical_accuracy: 0.4024 - val_loss: 0.1660 - val_categorical_accuracy: 0.4301\n",
      "Epoch 20/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1654 - categorical_accuracy: 0.4043 - val_loss: 0.1655 - val_categorical_accuracy: 0.4110\n",
      "Epoch 21/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1652 - categorical_accuracy: 0.4046 - val_loss: 0.1653 - val_categorical_accuracy: 0.4124\n",
      "Epoch 22/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1650 - categorical_accuracy: 0.4064 - val_loss: 0.1651 - val_categorical_accuracy: 0.4082\n",
      "Epoch 23/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1648 - categorical_accuracy: 0.4075 - val_loss: 0.1649 - val_categorical_accuracy: 0.4030\n",
      "Epoch 24/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1646 - categorical_accuracy: 0.4099 - val_loss: 0.1647 - val_categorical_accuracy: 0.4134\n",
      "Epoch 25/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1644 - categorical_accuracy: 0.4104 - val_loss: 0.1645 - val_categorical_accuracy: 0.4039\n",
      "Epoch 26/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1641 - categorical_accuracy: 0.4122 - val_loss: 0.1643 - val_categorical_accuracy: 0.4060\n",
      "Epoch 27/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1639 - categorical_accuracy: 0.4128 - val_loss: 0.1642 - val_categorical_accuracy: 0.4381\n",
      "Epoch 28/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1637 - categorical_accuracy: 0.4135 - val_loss: 0.1641 - val_categorical_accuracy: 0.4070\n",
      "Epoch 29/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1636 - categorical_accuracy: 0.4145 - val_loss: 0.1639 - val_categorical_accuracy: 0.4383\n",
      "Epoch 30/250\n",
      "264063/264063 [==============================] - 1s 6us/step - loss: 0.1634 - categorical_accuracy: 0.4163 - val_loss: 0.1637 - val_categorical_accuracy: 0.4307\n",
      "Epoch 31/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1632 - categorical_accuracy: 0.4173 - val_loss: 0.1634 - val_categorical_accuracy: 0.4229\n",
      "Epoch 32/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1630 - categorical_accuracy: 0.4184 - val_loss: 0.1633 - val_categorical_accuracy: 0.4169\n",
      "Epoch 33/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1628 - categorical_accuracy: 0.4209 - val_loss: 0.1631 - val_categorical_accuracy: 0.4188\n",
      "Epoch 34/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1627 - categorical_accuracy: 0.4214 - val_loss: 0.1629 - val_categorical_accuracy: 0.4230\n",
      "Epoch 35/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1625 - categorical_accuracy: 0.4219 - val_loss: 0.1627 - val_categorical_accuracy: 0.4396\n",
      "Epoch 36/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1623 - categorical_accuracy: 0.4242 - val_loss: 0.1625 - val_categorical_accuracy: 0.4218\n",
      "Epoch 37/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1622 - categorical_accuracy: 0.4235 - val_loss: 0.1624 - val_categorical_accuracy: 0.4388\n",
      "Epoch 38/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1620 - categorical_accuracy: 0.4263 - val_loss: 0.1623 - val_categorical_accuracy: 0.4468\n",
      "Epoch 39/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1619 - categorical_accuracy: 0.4271 - val_loss: 0.1620 - val_categorical_accuracy: 0.4212\n",
      "Epoch 40/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1617 - categorical_accuracy: 0.4279 - val_loss: 0.1620 - val_categorical_accuracy: 0.4127\n",
      "Epoch 41/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1616 - categorical_accuracy: 0.4287 - val_loss: 0.1619 - val_categorical_accuracy: 0.4149\n",
      "Epoch 42/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1614 - categorical_accuracy: 0.4299 - val_loss: 0.1616 - val_categorical_accuracy: 0.4240\n",
      "Epoch 43/250\n",
      "264063/264063 [==============================] - 1s 6us/step - loss: 0.1613 - categorical_accuracy: 0.4302 - val_loss: 0.1616 - val_categorical_accuracy: 0.4460\n",
      "Epoch 44/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1612 - categorical_accuracy: 0.4314 - val_loss: 0.1614 - val_categorical_accuracy: 0.4196\n",
      "Epoch 45/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1610 - categorical_accuracy: 0.4323 - val_loss: 0.1613 - val_categorical_accuracy: 0.4255\n",
      "Epoch 46/250\n",
      "264063/264063 [==============================] - 2s 7us/step - loss: 0.1609 - categorical_accuracy: 0.4323 - val_loss: 0.1611 - val_categorical_accuracy: 0.4511\n",
      "Epoch 47/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1607 - categorical_accuracy: 0.4356 - val_loss: 0.1610 - val_categorical_accuracy: 0.4267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1606 - categorical_accuracy: 0.4352 - val_loss: 0.1608 - val_categorical_accuracy: 0.4366\n",
      "Epoch 49/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1605 - categorical_accuracy: 0.4368 - val_loss: 0.1607 - val_categorical_accuracy: 0.4517\n",
      "Epoch 50/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1603 - categorical_accuracy: 0.4377 - val_loss: 0.1606 - val_categorical_accuracy: 0.4393\n",
      "Epoch 51/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1602 - categorical_accuracy: 0.4384 - val_loss: 0.1604 - val_categorical_accuracy: 0.4440\n",
      "Epoch 52/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1601 - categorical_accuracy: 0.4385 - val_loss: 0.1603 - val_categorical_accuracy: 0.4463\n",
      "Epoch 53/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1599 - categorical_accuracy: 0.4407 - val_loss: 0.1603 - val_categorical_accuracy: 0.4397\n",
      "Epoch 54/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1598 - categorical_accuracy: 0.4402 - val_loss: 0.1601 - val_categorical_accuracy: 0.4565\n",
      "Epoch 55/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1597 - categorical_accuracy: 0.4417 - val_loss: 0.1599 - val_categorical_accuracy: 0.4484\n",
      "Epoch 56/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1596 - categorical_accuracy: 0.4437 - val_loss: 0.1598 - val_categorical_accuracy: 0.4555\n",
      "Epoch 57/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1594 - categorical_accuracy: 0.4449 - val_loss: 0.1597 - val_categorical_accuracy: 0.4427\n",
      "Epoch 58/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1593 - categorical_accuracy: 0.4443 - val_loss: 0.1596 - val_categorical_accuracy: 0.4355\n",
      "Epoch 59/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1592 - categorical_accuracy: 0.4449 - val_loss: 0.1595 - val_categorical_accuracy: 0.4548\n",
      "Epoch 60/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1590 - categorical_accuracy: 0.4468 - val_loss: 0.1594 - val_categorical_accuracy: 0.4342\n",
      "Epoch 61/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1589 - categorical_accuracy: 0.4468 - val_loss: 0.1592 - val_categorical_accuracy: 0.4359\n",
      "Epoch 62/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1588 - categorical_accuracy: 0.4477 - val_loss: 0.1594 - val_categorical_accuracy: 0.4234\n",
      "Epoch 63/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1587 - categorical_accuracy: 0.4490 - val_loss: 0.1591 - val_categorical_accuracy: 0.4534\n",
      "Epoch 64/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1585 - categorical_accuracy: 0.4497 - val_loss: 0.1590 - val_categorical_accuracy: 0.4344\n",
      "Epoch 65/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1584 - categorical_accuracy: 0.4498 - val_loss: 0.1588 - val_categorical_accuracy: 0.4563\n",
      "Epoch 66/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1583 - categorical_accuracy: 0.4513 - val_loss: 0.1587 - val_categorical_accuracy: 0.4507\n",
      "Epoch 67/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1582 - categorical_accuracy: 0.4528 - val_loss: 0.1586 - val_categorical_accuracy: 0.4600\n",
      "Epoch 68/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1581 - categorical_accuracy: 0.4529 - val_loss: 0.1583 - val_categorical_accuracy: 0.4536\n",
      "Epoch 69/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1579 - categorical_accuracy: 0.4540 - val_loss: 0.1583 - val_categorical_accuracy: 0.4647\n",
      "Epoch 70/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1578 - categorical_accuracy: 0.4547 - val_loss: 0.1583 - val_categorical_accuracy: 0.4567\n",
      "Epoch 71/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1577 - categorical_accuracy: 0.4552 - val_loss: 0.1581 - val_categorical_accuracy: 0.4627\n",
      "Epoch 72/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1576 - categorical_accuracy: 0.4568 - val_loss: 0.1579 - val_categorical_accuracy: 0.4667\n",
      "Epoch 73/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1575 - categorical_accuracy: 0.4577 - val_loss: 0.1579 - val_categorical_accuracy: 0.4625\n",
      "Epoch 74/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1574 - categorical_accuracy: 0.4570 - val_loss: 0.1577 - val_categorical_accuracy: 0.4671\n",
      "Epoch 75/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1573 - categorical_accuracy: 0.4577 - val_loss: 0.1576 - val_categorical_accuracy: 0.4504\n",
      "Epoch 76/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1571 - categorical_accuracy: 0.4588 - val_loss: 0.1576 - val_categorical_accuracy: 0.4422\n",
      "Epoch 77/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1570 - categorical_accuracy: 0.4601 - val_loss: 0.1573 - val_categorical_accuracy: 0.4660\n",
      "Epoch 78/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1569 - categorical_accuracy: 0.4599 - val_loss: 0.1573 - val_categorical_accuracy: 0.4670\n",
      "Epoch 79/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1568 - categorical_accuracy: 0.4616 - val_loss: 0.1571 - val_categorical_accuracy: 0.4685\n",
      "Epoch 80/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1567 - categorical_accuracy: 0.4624 - val_loss: 0.1570 - val_categorical_accuracy: 0.4701\n",
      "Epoch 81/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1566 - categorical_accuracy: 0.4630 - val_loss: 0.1569 - val_categorical_accuracy: 0.4679\n",
      "Epoch 82/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1565 - categorical_accuracy: 0.4637 - val_loss: 0.1568 - val_categorical_accuracy: 0.4672\n",
      "Epoch 83/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1564 - categorical_accuracy: 0.4637 - val_loss: 0.1567 - val_categorical_accuracy: 0.4723\n",
      "Epoch 84/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1563 - categorical_accuracy: 0.4636 - val_loss: 0.1566 - val_categorical_accuracy: 0.4615\n",
      "Epoch 85/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1562 - categorical_accuracy: 0.4641 - val_loss: 0.1565 - val_categorical_accuracy: 0.4650\n",
      "Epoch 86/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1561 - categorical_accuracy: 0.4660 - val_loss: 0.1564 - val_categorical_accuracy: 0.4714\n",
      "Epoch 87/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1560 - categorical_accuracy: 0.4651 - val_loss: 0.1565 - val_categorical_accuracy: 0.4483\n",
      "Epoch 88/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1559 - categorical_accuracy: 0.4656 - val_loss: 0.1562 - val_categorical_accuracy: 0.4726\n",
      "Epoch 89/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1558 - categorical_accuracy: 0.4665 - val_loss: 0.1560 - val_categorical_accuracy: 0.4716\n",
      "Epoch 90/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1557 - categorical_accuracy: 0.4678 - val_loss: 0.1560 - val_categorical_accuracy: 0.4640\n",
      "Epoch 91/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1556 - categorical_accuracy: 0.4668 - val_loss: 0.1559 - val_categorical_accuracy: 0.4711\n",
      "Epoch 92/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1555 - categorical_accuracy: 0.4683 - val_loss: 0.1557 - val_categorical_accuracy: 0.4752\n",
      "Epoch 93/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1554 - categorical_accuracy: 0.4671 - val_loss: 0.1558 - val_categorical_accuracy: 0.4609\n",
      "Epoch 94/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1553 - categorical_accuracy: 0.4689 - val_loss: 0.1556 - val_categorical_accuracy: 0.4725\n",
      "Epoch 95/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1552 - categorical_accuracy: 0.4694 - val_loss: 0.1557 - val_categorical_accuracy: 0.4549\n",
      "Epoch 96/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1551 - categorical_accuracy: 0.4695 - val_loss: 0.1554 - val_categorical_accuracy: 0.4645\n",
      "Epoch 97/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1550 - categorical_accuracy: 0.4710 - val_loss: 0.1552 - val_categorical_accuracy: 0.4718\n",
      "Epoch 98/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1549 - categorical_accuracy: 0.4704 - val_loss: 0.1551 - val_categorical_accuracy: 0.4768\n",
      "Epoch 99/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1548 - categorical_accuracy: 0.4705 - val_loss: 0.1550 - val_categorical_accuracy: 0.4796\n",
      "Epoch 100/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1547 - categorical_accuracy: 0.4706 - val_loss: 0.1551 - val_categorical_accuracy: 0.4717\n",
      "Epoch 101/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1546 - categorical_accuracy: 0.4725 - val_loss: 0.1549 - val_categorical_accuracy: 0.4660\n",
      "Epoch 102/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1545 - categorical_accuracy: 0.4724 - val_loss: 0.1548 - val_categorical_accuracy: 0.4775\n",
      "Epoch 103/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1544 - categorical_accuracy: 0.4725 - val_loss: 0.1548 - val_categorical_accuracy: 0.4767\n",
      "Epoch 104/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1543 - categorical_accuracy: 0.4735 - val_loss: 0.1545 - val_categorical_accuracy: 0.4788\n",
      "Epoch 105/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1542 - categorical_accuracy: 0.4736 - val_loss: 0.1545 - val_categorical_accuracy: 0.4805\n",
      "Epoch 106/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1541 - categorical_accuracy: 0.4744 - val_loss: 0.1543 - val_categorical_accuracy: 0.4810\n",
      "Epoch 107/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1540 - categorical_accuracy: 0.4744 - val_loss: 0.1544 - val_categorical_accuracy: 0.4791\n",
      "Epoch 108/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1539 - categorical_accuracy: 0.4753 - val_loss: 0.1542 - val_categorical_accuracy: 0.4779\n",
      "Epoch 109/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1538 - categorical_accuracy: 0.4750 - val_loss: 0.1540 - val_categorical_accuracy: 0.4824\n",
      "Epoch 110/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1537 - categorical_accuracy: 0.4763 - val_loss: 0.1540 - val_categorical_accuracy: 0.4719\n",
      "Epoch 111/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1536 - categorical_accuracy: 0.4771 - val_loss: 0.1538 - val_categorical_accuracy: 0.4744\n",
      "Epoch 112/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1535 - categorical_accuracy: 0.4767 - val_loss: 0.1538 - val_categorical_accuracy: 0.4790\n",
      "Epoch 113/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1534 - categorical_accuracy: 0.4768 - val_loss: 0.1536 - val_categorical_accuracy: 0.4799\n",
      "Epoch 114/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1533 - categorical_accuracy: 0.4781 - val_loss: 0.1536 - val_categorical_accuracy: 0.4777\n",
      "Epoch 115/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1532 - categorical_accuracy: 0.4789 - val_loss: 0.1534 - val_categorical_accuracy: 0.4784\n",
      "Epoch 116/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1532 - categorical_accuracy: 0.4793 - val_loss: 0.1533 - val_categorical_accuracy: 0.4832\n",
      "Epoch 117/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1530 - categorical_accuracy: 0.4788 - val_loss: 0.1533 - val_categorical_accuracy: 0.4878\n",
      "Epoch 118/250\n",
      "264063/264063 [==============================] - 2s 7us/step - loss: 0.1530 - categorical_accuracy: 0.4787 - val_loss: 0.1533 - val_categorical_accuracy: 0.4881\n",
      "Epoch 119/250\n",
      "264063/264063 [==============================] - 2s 7us/step - loss: 0.1529 - categorical_accuracy: 0.4795 - val_loss: 0.1531 - val_categorical_accuracy: 0.4778\n",
      "Epoch 120/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1528 - categorical_accuracy: 0.4803 - val_loss: 0.1530 - val_categorical_accuracy: 0.4755\n",
      "Epoch 121/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1527 - categorical_accuracy: 0.4804 - val_loss: 0.1528 - val_categorical_accuracy: 0.4837\n",
      "Epoch 122/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1526 - categorical_accuracy: 0.4815 - val_loss: 0.1527 - val_categorical_accuracy: 0.4848\n",
      "Epoch 123/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1525 - categorical_accuracy: 0.4815 - val_loss: 0.1526 - val_categorical_accuracy: 0.4869\n",
      "Epoch 124/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1524 - categorical_accuracy: 0.4819 - val_loss: 0.1526 - val_categorical_accuracy: 0.4814\n",
      "Epoch 125/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1523 - categorical_accuracy: 0.4823 - val_loss: 0.1525 - val_categorical_accuracy: 0.4889\n",
      "Epoch 126/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1522 - categorical_accuracy: 0.4825 - val_loss: 0.1523 - val_categorical_accuracy: 0.4890\n",
      "Epoch 127/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1521 - categorical_accuracy: 0.4840 - val_loss: 0.1523 - val_categorical_accuracy: 0.4915\n",
      "Epoch 128/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1520 - categorical_accuracy: 0.4836 - val_loss: 0.1521 - val_categorical_accuracy: 0.4907\n",
      "Epoch 129/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1519 - categorical_accuracy: 0.4838 - val_loss: 0.1521 - val_categorical_accuracy: 0.4930\n",
      "Epoch 130/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1518 - categorical_accuracy: 0.4838 - val_loss: 0.1520 - val_categorical_accuracy: 0.4868\n",
      "Epoch 131/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1518 - categorical_accuracy: 0.4853 - val_loss: 0.1519 - val_categorical_accuracy: 0.4883\n",
      "Epoch 132/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1517 - categorical_accuracy: 0.4860 - val_loss: 0.1519 - val_categorical_accuracy: 0.4874\n",
      "Epoch 133/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1516 - categorical_accuracy: 0.4854 - val_loss: 0.1517 - val_categorical_accuracy: 0.4882\n",
      "Epoch 134/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1515 - categorical_accuracy: 0.4859 - val_loss: 0.1516 - val_categorical_accuracy: 0.4915\n",
      "Epoch 135/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1514 - categorical_accuracy: 0.4868 - val_loss: 0.1517 - val_categorical_accuracy: 0.4861\n",
      "Epoch 136/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1513 - categorical_accuracy: 0.4865 - val_loss: 0.1514 - val_categorical_accuracy: 0.4940\n",
      "Epoch 137/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1512 - categorical_accuracy: 0.4864 - val_loss: 0.1514 - val_categorical_accuracy: 0.4944\n",
      "Epoch 138/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1511 - categorical_accuracy: 0.4875 - val_loss: 0.1513 - val_categorical_accuracy: 0.4956\n",
      "Epoch 139/250\n",
      "264063/264063 [==============================] - 1s 6us/step - loss: 0.1510 - categorical_accuracy: 0.4881 - val_loss: 0.1512 - val_categorical_accuracy: 0.4939\n",
      "Epoch 140/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1509 - categorical_accuracy: 0.4889 - val_loss: 0.1511 - val_categorical_accuracy: 0.4928\n",
      "Epoch 141/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1509 - categorical_accuracy: 0.4893 - val_loss: 0.1511 - val_categorical_accuracy: 0.4882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1508 - categorical_accuracy: 0.4899 - val_loss: 0.1510 - val_categorical_accuracy: 0.4841\n",
      "Epoch 143/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1507 - categorical_accuracy: 0.4888 - val_loss: 0.1508 - val_categorical_accuracy: 0.4967\n",
      "Epoch 144/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1506 - categorical_accuracy: 0.4896 - val_loss: 0.1508 - val_categorical_accuracy: 0.4930\n",
      "Epoch 145/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1505 - categorical_accuracy: 0.4913 - val_loss: 0.1507 - val_categorical_accuracy: 0.4885\n",
      "Epoch 146/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1504 - categorical_accuracy: 0.4910 - val_loss: 0.1505 - val_categorical_accuracy: 0.4986\n",
      "Epoch 147/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1504 - categorical_accuracy: 0.4908 - val_loss: 0.1505 - val_categorical_accuracy: 0.4955\n",
      "Epoch 148/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1503 - categorical_accuracy: 0.4913 - val_loss: 0.1506 - val_categorical_accuracy: 0.4980\n",
      "Epoch 149/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1502 - categorical_accuracy: 0.4923 - val_loss: 0.1505 - val_categorical_accuracy: 0.4834\n",
      "Epoch 150/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1501 - categorical_accuracy: 0.4932 - val_loss: 0.1504 - val_categorical_accuracy: 0.4847\n",
      "Epoch 151/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1500 - categorical_accuracy: 0.4920 - val_loss: 0.1502 - val_categorical_accuracy: 0.4887\n",
      "Epoch 152/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1499 - categorical_accuracy: 0.4932 - val_loss: 0.1501 - val_categorical_accuracy: 0.4989\n",
      "Epoch 153/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1498 - categorical_accuracy: 0.4935 - val_loss: 0.1500 - val_categorical_accuracy: 0.4972\n",
      "Epoch 154/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1498 - categorical_accuracy: 0.4939 - val_loss: 0.1500 - val_categorical_accuracy: 0.4990\n",
      "Epoch 155/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1497 - categorical_accuracy: 0.4945 - val_loss: 0.1499 - val_categorical_accuracy: 0.4971\n",
      "Epoch 156/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1496 - categorical_accuracy: 0.4951 - val_loss: 0.1497 - val_categorical_accuracy: 0.5011\n",
      "Epoch 157/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1495 - categorical_accuracy: 0.4948 - val_loss: 0.1497 - val_categorical_accuracy: 0.4957\n",
      "Epoch 158/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1494 - categorical_accuracy: 0.4949 - val_loss: 0.1496 - val_categorical_accuracy: 0.4916\n",
      "Epoch 159/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1493 - categorical_accuracy: 0.4953 - val_loss: 0.1495 - val_categorical_accuracy: 0.4995\n",
      "Epoch 160/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1493 - categorical_accuracy: 0.4966 - val_loss: 0.1495 - val_categorical_accuracy: 0.4980\n",
      "Epoch 161/250\n",
      "264063/264063 [==============================] - 2s 8us/step - loss: 0.1492 - categorical_accuracy: 0.4966 - val_loss: 0.1494 - val_categorical_accuracy: 0.4979\n",
      "Epoch 162/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1491 - categorical_accuracy: 0.4970 - val_loss: 0.1494 - val_categorical_accuracy: 0.4983\n",
      "Epoch 163/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1490 - categorical_accuracy: 0.4970 - val_loss: 0.1493 - val_categorical_accuracy: 0.4937\n",
      "Epoch 164/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1490 - categorical_accuracy: 0.4973 - val_loss: 0.1491 - val_categorical_accuracy: 0.5008\n",
      "Epoch 165/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1489 - categorical_accuracy: 0.4972 - val_loss: 0.1490 - val_categorical_accuracy: 0.5052\n",
      "Epoch 166/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1488 - categorical_accuracy: 0.4992 - val_loss: 0.1490 - val_categorical_accuracy: 0.4962\n",
      "Epoch 167/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1487 - categorical_accuracy: 0.4987 - val_loss: 0.1490 - val_categorical_accuracy: 0.5008\n",
      "Epoch 168/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1487 - categorical_accuracy: 0.4989 - val_loss: 0.1488 - val_categorical_accuracy: 0.5051\n",
      "Epoch 169/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1486 - categorical_accuracy: 0.4994 - val_loss: 0.1487 - val_categorical_accuracy: 0.4991\n",
      "Epoch 170/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1485 - categorical_accuracy: 0.4999 - val_loss: 0.1487 - val_categorical_accuracy: 0.5041\n",
      "Epoch 171/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1484 - categorical_accuracy: 0.5001 - val_loss: 0.1487 - val_categorical_accuracy: 0.5059\n",
      "Epoch 172/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1484 - categorical_accuracy: 0.5003 - val_loss: 0.1488 - val_categorical_accuracy: 0.4905\n",
      "Epoch 173/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1483 - categorical_accuracy: 0.5004 - val_loss: 0.1484 - val_categorical_accuracy: 0.5055\n",
      "Epoch 174/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1482 - categorical_accuracy: 0.5010 - val_loss: 0.1484 - val_categorical_accuracy: 0.5068\n",
      "Epoch 175/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1482 - categorical_accuracy: 0.5007 - val_loss: 0.1484 - val_categorical_accuracy: 0.5043\n",
      "Epoch 176/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1481 - categorical_accuracy: 0.5015 - val_loss: 0.1483 - val_categorical_accuracy: 0.5048\n",
      "Epoch 177/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1480 - categorical_accuracy: 0.5011 - val_loss: 0.1482 - val_categorical_accuracy: 0.5069\n",
      "Epoch 178/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1480 - categorical_accuracy: 0.5006 - val_loss: 0.1481 - val_categorical_accuracy: 0.5095\n",
      "Epoch 179/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1479 - categorical_accuracy: 0.5019 - val_loss: 0.1482 - val_categorical_accuracy: 0.5070\n",
      "Epoch 180/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1478 - categorical_accuracy: 0.5024 - val_loss: 0.1480 - val_categorical_accuracy: 0.5041\n",
      "Epoch 181/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1478 - categorical_accuracy: 0.5017 - val_loss: 0.1480 - val_categorical_accuracy: 0.5067\n",
      "Epoch 182/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1477 - categorical_accuracy: 0.5033 - val_loss: 0.1479 - val_categorical_accuracy: 0.5092\n",
      "Epoch 183/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1477 - categorical_accuracy: 0.5029 - val_loss: 0.1478 - val_categorical_accuracy: 0.5087\n",
      "Epoch 184/250\n",
      "264063/264063 [==============================] - 2s 9us/step - loss: 0.1476 - categorical_accuracy: 0.5038 - val_loss: 0.1478 - val_categorical_accuracy: 0.5018\n",
      "Epoch 185/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1475 - categorical_accuracy: 0.5035 - val_loss: 0.1479 - val_categorical_accuracy: 0.5073\n",
      "Epoch 186/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1475 - categorical_accuracy: 0.5033 - val_loss: 0.1478 - val_categorical_accuracy: 0.5040\n",
      "Epoch 187/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1474 - categorical_accuracy: 0.5038 - val_loss: 0.1476 - val_categorical_accuracy: 0.5045\n",
      "Epoch 188/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1473 - categorical_accuracy: 0.5045 - val_loss: 0.1475 - val_categorical_accuracy: 0.5064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1473 - categorical_accuracy: 0.5039 - val_loss: 0.1476 - val_categorical_accuracy: 0.5069\n",
      "Epoch 190/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1472 - categorical_accuracy: 0.5048 - val_loss: 0.1474 - val_categorical_accuracy: 0.5115\n",
      "Epoch 191/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1472 - categorical_accuracy: 0.5046 - val_loss: 0.1475 - val_categorical_accuracy: 0.5045\n",
      "Epoch 192/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1471 - categorical_accuracy: 0.5049 - val_loss: 0.1474 - val_categorical_accuracy: 0.5056\n",
      "Epoch 193/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1471 - categorical_accuracy: 0.5055 - val_loss: 0.1475 - val_categorical_accuracy: 0.5024\n",
      "Epoch 194/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1470 - categorical_accuracy: 0.5055 - val_loss: 0.1473 - val_categorical_accuracy: 0.5099\n",
      "Epoch 195/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1470 - categorical_accuracy: 0.5058 - val_loss: 0.1472 - val_categorical_accuracy: 0.5093\n",
      "Epoch 196/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1469 - categorical_accuracy: 0.5056 - val_loss: 0.1471 - val_categorical_accuracy: 0.5096\n",
      "Epoch 197/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1469 - categorical_accuracy: 0.5060 - val_loss: 0.1471 - val_categorical_accuracy: 0.5086\n",
      "Epoch 198/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1468 - categorical_accuracy: 0.5062 - val_loss: 0.1471 - val_categorical_accuracy: 0.5034\n",
      "Epoch 199/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1468 - categorical_accuracy: 0.5060 - val_loss: 0.1470 - val_categorical_accuracy: 0.5137\n",
      "Epoch 200/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1467 - categorical_accuracy: 0.5068 - val_loss: 0.1469 - val_categorical_accuracy: 0.5113\n",
      "Epoch 201/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1467 - categorical_accuracy: 0.5072 - val_loss: 0.1471 - val_categorical_accuracy: 0.5079\n",
      "Epoch 202/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1466 - categorical_accuracy: 0.5073 - val_loss: 0.1470 - val_categorical_accuracy: 0.5027\n",
      "Epoch 203/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1466 - categorical_accuracy: 0.5076 - val_loss: 0.1468 - val_categorical_accuracy: 0.5117\n",
      "Epoch 204/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1465 - categorical_accuracy: 0.5075 - val_loss: 0.1467 - val_categorical_accuracy: 0.5136\n",
      "Epoch 205/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1465 - categorical_accuracy: 0.5075 - val_loss: 0.1468 - val_categorical_accuracy: 0.4999\n",
      "Epoch 206/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1464 - categorical_accuracy: 0.5077 - val_loss: 0.1470 - val_categorical_accuracy: 0.5057\n",
      "Epoch 207/250\n",
      "264063/264063 [==============================] - 2s 7us/step - loss: 0.1464 - categorical_accuracy: 0.5081 - val_loss: 0.1468 - val_categorical_accuracy: 0.5094\n",
      "Epoch 208/250\n",
      "264063/264063 [==============================] - 1s 6us/step - loss: 0.1464 - categorical_accuracy: 0.5069 - val_loss: 0.1466 - val_categorical_accuracy: 0.5066\n",
      "Epoch 209/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1463 - categorical_accuracy: 0.5081 - val_loss: 0.1465 - val_categorical_accuracy: 0.5130\n",
      "Epoch 210/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1463 - categorical_accuracy: 0.5081 - val_loss: 0.1464 - val_categorical_accuracy: 0.5141\n",
      "Epoch 211/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1462 - categorical_accuracy: 0.5080 - val_loss: 0.1464 - val_categorical_accuracy: 0.5128\n",
      "Epoch 212/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1462 - categorical_accuracy: 0.5082 - val_loss: 0.1464 - val_categorical_accuracy: 0.5109\n",
      "Epoch 213/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1461 - categorical_accuracy: 0.5090 - val_loss: 0.1463 - val_categorical_accuracy: 0.5133\n",
      "Epoch 214/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1461 - categorical_accuracy: 0.5088 - val_loss: 0.1463 - val_categorical_accuracy: 0.5150\n",
      "Epoch 215/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1460 - categorical_accuracy: 0.5087 - val_loss: 0.1462 - val_categorical_accuracy: 0.5123\n",
      "Epoch 216/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1460 - categorical_accuracy: 0.5089 - val_loss: 0.1462 - val_categorical_accuracy: 0.5146\n",
      "Epoch 217/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1460 - categorical_accuracy: 0.5098 - val_loss: 0.1462 - val_categorical_accuracy: 0.5162\n",
      "Epoch 218/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1459 - categorical_accuracy: 0.5093 - val_loss: 0.1461 - val_categorical_accuracy: 0.5130\n",
      "Epoch 219/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1459 - categorical_accuracy: 0.5090 - val_loss: 0.1460 - val_categorical_accuracy: 0.5151\n",
      "Epoch 220/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1458 - categorical_accuracy: 0.5105 - val_loss: 0.1460 - val_categorical_accuracy: 0.5139\n",
      "Epoch 221/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1458 - categorical_accuracy: 0.5102 - val_loss: 0.1461 - val_categorical_accuracy: 0.5068\n",
      "Epoch 222/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1458 - categorical_accuracy: 0.5104 - val_loss: 0.1460 - val_categorical_accuracy: 0.5127\n",
      "Epoch 223/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1457 - categorical_accuracy: 0.5101 - val_loss: 0.1458 - val_categorical_accuracy: 0.5161\n",
      "Epoch 224/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1457 - categorical_accuracy: 0.5100 - val_loss: 0.1461 - val_categorical_accuracy: 0.5116\n",
      "Epoch 225/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1456 - categorical_accuracy: 0.5106 - val_loss: 0.1459 - val_categorical_accuracy: 0.5095\n",
      "Epoch 226/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1456 - categorical_accuracy: 0.5111 - val_loss: 0.1458 - val_categorical_accuracy: 0.5104\n",
      "Epoch 227/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1456 - categorical_accuracy: 0.5107 - val_loss: 0.1457 - val_categorical_accuracy: 0.5131\n",
      "Epoch 228/250\n",
      "264063/264063 [==============================] - 2s 6us/step - loss: 0.1455 - categorical_accuracy: 0.5114 - val_loss: 0.1458 - val_categorical_accuracy: 0.5109\n",
      "Epoch 229/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1455 - categorical_accuracy: 0.5114 - val_loss: 0.1457 - val_categorical_accuracy: 0.5170\n",
      "Epoch 230/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1455 - categorical_accuracy: 0.5121 - val_loss: 0.1456 - val_categorical_accuracy: 0.5119\n",
      "Epoch 231/250\n",
      "264063/264063 [==============================] - 2s 7us/step - loss: 0.1454 - categorical_accuracy: 0.5109 - val_loss: 0.1456 - val_categorical_accuracy: 0.5162\n",
      "Epoch 232/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1454 - categorical_accuracy: 0.5104 - val_loss: 0.1456 - val_categorical_accuracy: 0.5171\n",
      "Epoch 233/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1454 - categorical_accuracy: 0.5126 - val_loss: 0.1455 - val_categorical_accuracy: 0.5114\n",
      "Epoch 234/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1453 - categorical_accuracy: 0.5114 - val_loss: 0.1455 - val_categorical_accuracy: 0.5129\n",
      "Epoch 235/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1453 - categorical_accuracy: 0.5123 - val_loss: 0.1454 - val_categorical_accuracy: 0.5177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1453 - categorical_accuracy: 0.5122 - val_loss: 0.1454 - val_categorical_accuracy: 0.5174\n",
      "Epoch 237/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1452 - categorical_accuracy: 0.5120 - val_loss: 0.1455 - val_categorical_accuracy: 0.5086\n",
      "Epoch 238/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1452 - categorical_accuracy: 0.5126 - val_loss: 0.1454 - val_categorical_accuracy: 0.5167\n",
      "Epoch 239/250\n",
      "264063/264063 [==============================] - 1s 4us/step - loss: 0.1452 - categorical_accuracy: 0.5116 - val_loss: 0.1453 - val_categorical_accuracy: 0.5170\n",
      "Epoch 240/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1451 - categorical_accuracy: 0.5129 - val_loss: 0.1453 - val_categorical_accuracy: 0.5177\n",
      "Epoch 241/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1451 - categorical_accuracy: 0.5118 - val_loss: 0.1454 - val_categorical_accuracy: 0.5140\n",
      "Epoch 242/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1450 - categorical_accuracy: 0.5139 - val_loss: 0.1453 - val_categorical_accuracy: 0.5169\n",
      "Epoch 243/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1450 - categorical_accuracy: 0.5134 - val_loss: 0.1453 - val_categorical_accuracy: 0.5181\n",
      "Epoch 244/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1450 - categorical_accuracy: 0.5128 - val_loss: 0.1452 - val_categorical_accuracy: 0.5166\n",
      "Epoch 245/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1449 - categorical_accuracy: 0.5140 - val_loss: 0.1451 - val_categorical_accuracy: 0.5174\n",
      "Epoch 246/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1449 - categorical_accuracy: 0.5130 - val_loss: 0.1451 - val_categorical_accuracy: 0.5190\n",
      "Epoch 247/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1449 - categorical_accuracy: 0.5134 - val_loss: 0.1451 - val_categorical_accuracy: 0.5189\n",
      "Epoch 248/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1449 - categorical_accuracy: 0.5139 - val_loss: 0.1452 - val_categorical_accuracy: 0.5090\n",
      "Epoch 249/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1448 - categorical_accuracy: 0.5145 - val_loss: 0.1449 - val_categorical_accuracy: 0.5189\n",
      "Epoch 250/250\n",
      "264063/264063 [==============================] - 1s 5us/step - loss: 0.1448 - categorical_accuracy: 0.5140 - val_loss: 0.1450 - val_categorical_accuracy: 0.5169\n"
     ]
    }
   ],
   "source": [
    "history = clf.fit(trainX,onehot_encoded_train,\n",
    "                 batch_size = 200, epochs = 250,\n",
    "                 verbose = 1,\n",
    "                 validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 3, 1, 2, 1, 3, 1, 0, 0, 1, 2, 2, 1, 2, 3, 2, 0, 1, 3, 2,\n",
       "        0, 2, 2, 1, 1, 3, 3, 0, 2, 3, 3, 3, 0, 0, 3, 1, 0, 1, 2, 1, 3, 2,\n",
       "        1, 3, 2, 3, 1, 2, 2, 3, 1, 2, 1, 2, 1, 2, 3, 0, 0, 2, 1, 1, 1, 3,\n",
       "        0, 2, 1, 3, 1, 3, 1, 1, 3, 0, 1, 2, 1, 3, 0, 3, 2, 1, 3, 2, 3, 0,\n",
       "        3, 0, 0, 0, 2, 1, 3, 1, 0, 3, 1], dtype=int64),\n",
       " array([2, 2, 3, 3, 3, 2, 1, 3, 1, 0, 1, 2, 2, 2, 2, 1, 3, 3, 2, 2, 3, 2,\n",
       "        2, 2, 2, 2, 3, 3, 3, 0, 3, 3, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 3, 1,\n",
       "        2, 2, 2, 3, 1, 2, 2, 3, 1, 3, 2, 2, 3, 0, 2, 3, 0, 2, 0, 1, 1, 3,\n",
       "        3, 3, 2, 3, 2, 3, 3, 2, 3, 2, 1, 2, 2, 3, 2, 3, 3, 1, 3, 3, 3, 0,\n",
       "        3, 1, 0, 3, 2, 3, 2, 2, 2, 3, 1], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "testY[1:100]-1, clf.predict_classes(testX[1:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73352/73352 [==============================] - 1s 9us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14520121206112888, 0.5158686879703348]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(testX,onehot_encoded_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and weights\n",
    "clf_json = clf.to_json()\n",
    "with open(\"NN_OwnVoice_36-20-4_inputs_uniBF.json\", \"w\") as json_file:\n",
    "    json_file.write(clf_json)\n",
    "    \n",
    "clf.save_weights(\"NN_OwnVoice_36-20-4_inputs_uniBF_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('TestX_NN_OwnVoice_uniBF_separation',testX), np.save('TestY_NN_OwnVoice_uniBF_separation',testY),\n",
    "np.save('OneHot_testY_uniBF_separation',onehot_encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73352/73352 [==============================] - 1s 8us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14520121206112888, 0.5158686879703348]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(testX,onehot_encoded_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....................................................x...............................s...................................x....................................s...s......ss.ss..............................................................................ss....................ssssss...................................................................x....x.........................x......x.................................................ssss..................\n",
      "----------------------------------------------------------------------\n",
      "Ran 457 tests in 2.785s\n",
      "\n",
      "OK (skipped=19, expected failures=6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=457 errors=0 failures=0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py.run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 200,\n",
       " 'epochs': 150,\n",
       " 'steps': None,\n",
       " 'samples': 640737,\n",
       " 'verbose': 1,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss',\n",
       "  'categorical_accuracy',\n",
       "  'val_loss',\n",
       "  'val_categorical_accuracy']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
