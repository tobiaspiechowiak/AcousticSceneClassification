{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import pandas as pd\n",
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data \n",
    "path = 'x:/Steering/Recordings/Processed/'\n",
    "data, fs = sf.read(path + 'ERB=2.wav')\n",
    "classes = pd.read_csv(path + 'Classes_2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:len(data)-1,:data.shape[1]] #775361\n",
    "Y = classes.values[:,0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSteps = 60;\n",
    "features = X.shape[1];\n",
    "#reshape the taining set to (samples, timeSteps, features)\n",
    "tmp = X[:int(len(X)/timeSteps)*timeSteps]\n",
    "X = tmp.reshape(int(len(tmp)/timeSteps),timeSteps,features)\n",
    "\n",
    "tmp = Y[:int(len(Y)/timeSteps)*timeSteps]\n",
    "Y = tmp.reshape(int(len(tmp)/timeSteps),timeSteps,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14133, 60, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY_OHC = keras.utils.to_categorical(trainY)\n",
    "testY_OHC = keras.utils.to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14133, 60, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY_OHC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC removal \n",
    "trainX -= (np.mean(trainX, axis=0) + 1e-8)\n",
    "testX -= (np.mean(testX, axis=0) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14133, 60, 108) (14133, 60, 5)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, trainY_OHC.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14133, 60, 5), (14133, 60, 108))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY_OHC.shape, trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#design the net\n",
    "model.add(keras.layers.GRU(56,input_shape = (timeSteps, features),activation='tanh',\n",
    "                            return_sequences=True))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Dense(5,activation='softmax',\n",
    "                                                          kernel_regularizer=keras.regularizers.l2(0.001))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling\n",
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11306 samples, validate on 2827 samples\n",
      "Epoch 1/50\n",
      "11306/11306 [==============================] - 11s 942us/step - loss: 0.1572 - acc: 0.3427 - val_loss: 0.1529 - val_acc: 0.3576\n",
      "Epoch 2/50\n",
      "11306/11306 [==============================] - 10s 848us/step - loss: 0.1526 - acc: 0.3443 - val_loss: 0.1494 - val_acc: 0.3648\n",
      "Epoch 3/50\n",
      "11306/11306 [==============================] - 10s 852us/step - loss: 0.1320 - acc: 0.4406 - val_loss: 0.1248 - val_acc: 0.4837\n",
      "Epoch 4/50\n",
      "11306/11306 [==============================] - 10s 860us/step - loss: 0.1172 - acc: 0.5504 - val_loss: 0.1127 - val_acc: 0.5697\n",
      "Epoch 5/50\n",
      "11306/11306 [==============================] - 10s 845us/step - loss: 0.1049 - acc: 0.6180 - val_loss: 0.1040 - val_acc: 0.6228\n",
      "Epoch 6/50\n",
      "11306/11306 [==============================] - 10s 851us/step - loss: 0.0975 - acc: 0.6481 - val_loss: 0.0966 - val_acc: 0.6435\n",
      "Epoch 7/50\n",
      "11306/11306 [==============================] - 10s 847us/step - loss: 0.0914 - acc: 0.6711 - val_loss: 0.0895 - val_acc: 0.6799\n",
      "Epoch 8/50\n",
      "11306/11306 [==============================] - 10s 858us/step - loss: 0.0880 - acc: 0.6842 - val_loss: 0.0872 - val_acc: 0.6848\n",
      "Epoch 9/50\n",
      "11306/11306 [==============================] - 10s 854us/step - loss: 0.0856 - acc: 0.6938 - val_loss: 0.0876 - val_acc: 0.6812\n",
      "Epoch 10/50\n",
      "11306/11306 [==============================] - 10s 861us/step - loss: 0.0839 - acc: 0.6990 - val_loss: 0.0852 - val_acc: 0.6963\n",
      "Epoch 11/50\n",
      "11306/11306 [==============================] - 9s 805us/step - loss: 0.0820 - acc: 0.7045 - val_loss: 0.0850 - val_acc: 0.6899\n",
      "Epoch 12/50\n",
      "11306/11306 [==============================] - 8s 742us/step - loss: 0.0802 - acc: 0.7115 - val_loss: 0.0872 - val_acc: 0.6750\n",
      "Epoch 13/50\n",
      "11306/11306 [==============================] - 9s 756us/step - loss: 0.0791 - acc: 0.7160 - val_loss: 0.0781 - val_acc: 0.7159\n",
      "Epoch 14/50\n",
      "11306/11306 [==============================] - 8s 746us/step - loss: 0.0769 - acc: 0.7271 - val_loss: 0.0773 - val_acc: 0.7273\n",
      "Epoch 15/50\n",
      "11306/11306 [==============================] - 8s 742us/step - loss: 0.0748 - acc: 0.7388 - val_loss: 0.0739 - val_acc: 0.7440\n",
      "Epoch 16/50\n",
      "11306/11306 [==============================] - 8s 746us/step - loss: 0.0720 - acc: 0.7538 - val_loss: 0.0719 - val_acc: 0.7514\n",
      "Epoch 17/50\n",
      "11306/11306 [==============================] - 8s 733us/step - loss: 0.0705 - acc: 0.7597 - val_loss: 0.0719 - val_acc: 0.7521\n",
      "Epoch 18/50\n",
      "11306/11306 [==============================] - 8s 741us/step - loss: 0.0703 - acc: 0.7630 - val_loss: 0.0753 - val_acc: 0.7470\n",
      "Epoch 19/50\n",
      "11306/11306 [==============================] - 8s 741us/step - loss: 0.0720 - acc: 0.7574 - val_loss: 0.0697 - val_acc: 0.7634\n",
      "Epoch 20/50\n",
      "11306/11306 [==============================] - 8s 742us/step - loss: 0.0671 - acc: 0.7754 - val_loss: 0.0677 - val_acc: 0.7721\n",
      "Epoch 21/50\n",
      "11306/11306 [==============================] - 8s 739us/step - loss: 0.0659 - acc: 0.7796 - val_loss: 0.0678 - val_acc: 0.7725\n",
      "Epoch 22/50\n",
      "11306/11306 [==============================] - 8s 742us/step - loss: 0.0648 - acc: 0.7839 - val_loss: 0.0655 - val_acc: 0.7792\n",
      "Epoch 23/50\n",
      "11306/11306 [==============================] - 8s 740us/step - loss: 0.0646 - acc: 0.7841 - val_loss: 0.0650 - val_acc: 0.7804\n",
      "Epoch 24/50\n",
      "11306/11306 [==============================] - 8s 744us/step - loss: 0.0636 - acc: 0.7879 - val_loss: 0.0646 - val_acc: 0.7831\n",
      "Epoch 25/50\n",
      "11306/11306 [==============================] - 8s 743us/step - loss: 0.0625 - acc: 0.7931 - val_loss: 0.0644 - val_acc: 0.7874\n",
      "Epoch 26/50\n",
      "11306/11306 [==============================] - 8s 741us/step - loss: 0.0624 - acc: 0.7927 - val_loss: 0.0686 - val_acc: 0.7597\n",
      "Epoch 27/50\n",
      "11306/11306 [==============================] - 8s 742us/step - loss: 0.0788 - acc: 0.7370 - val_loss: 0.0711 - val_acc: 0.7731\n",
      "Epoch 28/50\n",
      "11306/11306 [==============================] - 8s 740us/step - loss: 0.0676 - acc: 0.7802 - val_loss: 0.0653 - val_acc: 0.7843\n",
      "Epoch 29/50\n",
      "11306/11306 [==============================] - 8s 738us/step - loss: 0.0655 - acc: 0.7834 - val_loss: 0.0649 - val_acc: 0.7843\n",
      "Epoch 30/50\n",
      "11306/11306 [==============================] - 8s 740us/step - loss: 0.0616 - acc: 0.7966 - val_loss: 0.0627 - val_acc: 0.7923\n",
      "Epoch 31/50\n",
      "11306/11306 [==============================] - 8s 735us/step - loss: 0.0610 - acc: 0.7974 - val_loss: 0.0622 - val_acc: 0.7925\n",
      "Epoch 32/50\n",
      "11306/11306 [==============================] - 8s 735us/step - loss: 0.0601 - acc: 0.8006 - val_loss: 0.0614 - val_acc: 0.7942\n",
      "Epoch 33/50\n",
      "11306/11306 [==============================] - 8s 741us/step - loss: 0.0594 - acc: 0.8029 - val_loss: 0.0605 - val_acc: 0.7982\n",
      "Epoch 34/50\n",
      "11306/11306 [==============================] - 8s 739us/step - loss: 0.0583 - acc: 0.8076 - val_loss: 0.0610 - val_acc: 0.7977\n",
      "Epoch 35/50\n",
      "11306/11306 [==============================] - 8s 739us/step - loss: 0.0586 - acc: 0.8068 - val_loss: 0.0594 - val_acc: 0.8009\n",
      "Epoch 36/50\n",
      "11306/11306 [==============================] - 8s 733us/step - loss: 0.0577 - acc: 0.8088 - val_loss: 0.0596 - val_acc: 0.8007\n",
      "Epoch 37/50\n",
      "11306/11306 [==============================] - 8s 743us/step - loss: 0.0574 - acc: 0.8100 - val_loss: 0.0669 - val_acc: 0.7757\n",
      "Epoch 38/50\n",
      "11306/11306 [==============================] - 8s 739us/step - loss: 0.0568 - acc: 0.8128 - val_loss: 0.0603 - val_acc: 0.8033\n",
      "Epoch 39/50\n",
      "11306/11306 [==============================] - 8s 740us/step - loss: 0.0566 - acc: 0.8122 - val_loss: 0.0587 - val_acc: 0.8043\n",
      "Epoch 40/50\n",
      "11306/11306 [==============================] - 8s 742us/step - loss: 0.0562 - acc: 0.8140 - val_loss: 0.0583 - val_acc: 0.8064\n",
      "Epoch 41/50\n",
      "11306/11306 [==============================] - 8s 741us/step - loss: 0.0559 - acc: 0.8159 - val_loss: 0.0566 - val_acc: 0.8113\n",
      "Epoch 42/50\n",
      "11306/11306 [==============================] - 8s 738us/step - loss: 0.0556 - acc: 0.8165 - val_loss: 0.0584 - val_acc: 0.8044\n",
      "Epoch 43/50\n",
      "11306/11306 [==============================] - 8s 736us/step - loss: 0.0547 - acc: 0.8198 - val_loss: 0.0568 - val_acc: 0.8126\n",
      "Epoch 44/50\n",
      "11306/11306 [==============================] - 8s 742us/step - loss: 0.0565 - acc: 0.8132 - val_loss: 0.0600 - val_acc: 0.8050\n",
      "Epoch 45/50\n",
      "11306/11306 [==============================] - 8s 745us/step - loss: 0.0544 - acc: 0.8218 - val_loss: 0.0582 - val_acc: 0.8058\n",
      "Epoch 46/50\n",
      "11306/11306 [==============================] - 8s 751us/step - loss: 0.0550 - acc: 0.8195 - val_loss: 0.0569 - val_acc: 0.8119\n",
      "Epoch 47/50\n",
      "11306/11306 [==============================] - 8s 747us/step - loss: 0.0532 - acc: 0.8244 - val_loss: 0.0557 - val_acc: 0.8171\n",
      "Epoch 48/50\n",
      "11306/11306 [==============================] - 8s 745us/step - loss: 0.0534 - acc: 0.8251 - val_loss: 0.0567 - val_acc: 0.8147\n",
      "Epoch 49/50\n",
      "11306/11306 [==============================] - 8s 739us/step - loss: 0.0523 - acc: 0.8280 - val_loss: 0.0567 - val_acc: 0.8124\n",
      "Epoch 50/50\n",
      "11306/11306 [==============================] - 8s 738us/step - loss: 0.0539 - acc: 0.8240 - val_loss: 0.0550 - val_acc: 0.8200\n"
     ]
    }
   ],
   "source": [
    "#fit model\n",
    "history = model.fit(trainX,trainY_OHC, epochs = 50, batch_size=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3534/3534 [==============================] - 1s 323us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0556800492786727, 0.821354462591753]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX,testY_OHC,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and weights\n",
    "model_json = model.to_json()\n",
    "with open(\"GRU_56-60-5.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(\"GRU_56-60-5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('TestX_GRU_56-60-5',testX), np.save('TestY_GRU_56-60-5',testY),\n",
    "np.save('OneHot_GRU_56-60-5',testY_OHC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.15285083605157726,\n",
       "  0.1494131933253352,\n",
       "  0.12482659901394455,\n",
       "  0.11272078588325564,\n",
       "  0.10401336430217169,\n",
       "  0.09657130852673726,\n",
       "  0.08952048722408161,\n",
       "  0.0872020337073087,\n",
       "  0.0876023923740355,\n",
       "  0.08520975947474944,\n",
       "  0.08497841450374878,\n",
       "  0.0872438254502286,\n",
       "  0.07810585750817071,\n",
       "  0.07730128166740506,\n",
       "  0.07392233663917558,\n",
       "  0.07190898260833688,\n",
       "  0.071862984755708,\n",
       "  0.07531572504250414,\n",
       "  0.06969640566992136,\n",
       "  0.06772108022999881,\n",
       "  0.06777081754800494,\n",
       "  0.06550664631014036,\n",
       "  0.06503707126209919,\n",
       "  0.06461524643164707,\n",
       "  0.06443773307957791,\n",
       "  0.06857545808389873,\n",
       "  0.07108280780851356,\n",
       "  0.06525806079051669,\n",
       "  0.06490086635352657,\n",
       "  0.06265588299488911,\n",
       "  0.06220484001553434,\n",
       "  0.0614031992225437,\n",
       "  0.06052539451097194,\n",
       "  0.06098558035948313,\n",
       "  0.059377839732789976,\n",
       "  0.059561866606698675,\n",
       "  0.06691431185757056,\n",
       "  0.060344855702667635,\n",
       "  0.05873748310092147,\n",
       "  0.05830091722428187,\n",
       "  0.056607461580232464,\n",
       "  0.05840585266543354,\n",
       "  0.05683074456313114,\n",
       "  0.05997309230497291,\n",
       "  0.05817411834954541,\n",
       "  0.05691244640312812,\n",
       "  0.0557295350106858,\n",
       "  0.05666937560454501,\n",
       "  0.05669113999047505,\n",
       "  0.05498769548584895],\n",
       " 'val_acc': [0.35764060987783564,\n",
       "  0.3647800980417139,\n",
       "  0.4837165425133275,\n",
       "  0.5696557052446668,\n",
       "  0.6227567499081154,\n",
       "  0.6434559644343872,\n",
       "  0.6798844470082133,\n",
       "  0.6847836336441836,\n",
       "  0.6811578839880272,\n",
       "  0.6963035020045607,\n",
       "  0.6899127461356158,\n",
       "  0.6749793679038669,\n",
       "  0.7159297254383248,\n",
       "  0.7272550397683337,\n",
       "  0.7440455134656263,\n",
       "  0.7514090331190248,\n",
       "  0.7520575447262999,\n",
       "  0.7469579044440883,\n",
       "  0.763382857791265,\n",
       "  0.7721082445670236,\n",
       "  0.772473762703313,\n",
       "  0.7791710890431601,\n",
       "  0.7803678819346352,\n",
       "  0.783085722214011,\n",
       "  0.7873835644411628,\n",
       "  0.7596686708028974,\n",
       "  0.7730869014102071,\n",
       "  0.7843178873522609,\n",
       "  0.7843237869681341,\n",
       "  0.7923122256899369,\n",
       "  0.7925067791721194,\n",
       "  0.7941634240064429,\n",
       "  0.7982018616539368,\n",
       "  0.7977184295274784,\n",
       "  0.8008725340812503,\n",
       "  0.8007015705656828,\n",
       "  0.7756750372597215,\n",
       "  0.8032720160855393,\n",
       "  0.8042978422566694,\n",
       "  0.8063730671922773,\n",
       "  0.8113371088262746,\n",
       "  0.8044216491790639,\n",
       "  0.812575168941904,\n",
       "  0.8049876262958623,\n",
       "  0.8057835164068443,\n",
       "  0.8119325538300608,\n",
       "  0.8171383076899879,\n",
       "  0.8146503947841265,\n",
       "  0.8124159835529361,\n",
       "  0.8199799562411381],\n",
       " 'loss': [0.15720359299133546,\n",
       "  0.15257242192014558,\n",
       "  0.13202454455100646,\n",
       "  0.11715733636333397,\n",
       "  0.10486323070377454,\n",
       "  0.09746435687654992,\n",
       "  0.09142122396073382,\n",
       "  0.08803400399277701,\n",
       "  0.08555592700322391,\n",
       "  0.08386433807523108,\n",
       "  0.08197433717434183,\n",
       "  0.080191350199497,\n",
       "  0.07905571678428971,\n",
       "  0.07693291015036018,\n",
       "  0.07483956263763555,\n",
       "  0.07196226517091425,\n",
       "  0.07047405149395564,\n",
       "  0.07032702197171661,\n",
       "  0.07195316591838304,\n",
       "  0.06705085577351971,\n",
       "  0.065927474947497,\n",
       "  0.0647698428910822,\n",
       "  0.06455164988304943,\n",
       "  0.06362309520373867,\n",
       "  0.062454438844935234,\n",
       "  0.06240972045755652,\n",
       "  0.07881605065139904,\n",
       "  0.06761354526747713,\n",
       "  0.06554285544021012,\n",
       "  0.06162109759311834,\n",
       "  0.06100454125747773,\n",
       "  0.060111261275559845,\n",
       "  0.0594218034081737,\n",
       "  0.058336833799341896,\n",
       "  0.05857413888765756,\n",
       "  0.057742481565245606,\n",
       "  0.05738506954859869,\n",
       "  0.05684677125085735,\n",
       "  0.05664507207073049,\n",
       "  0.056164553849260175,\n",
       "  0.055919859414683304,\n",
       "  0.055609337881065125,\n",
       "  0.0547264376706293,\n",
       "  0.056462250325374747,\n",
       "  0.05436616362936303,\n",
       "  0.05497589836866797,\n",
       "  0.05324474037452734,\n",
       "  0.053367519939333787,\n",
       "  0.05234774958896527,\n",
       "  0.05387279983196726],\n",
       " 'acc': [0.3427103608503988,\n",
       "  0.34433928956853466,\n",
       "  0.440597912731918,\n",
       "  0.5504216059855227,\n",
       "  0.6179963422996184,\n",
       "  0.6480688730657744,\n",
       "  0.6711244772603696,\n",
       "  0.6842104478597684,\n",
       "  0.6937909087901957,\n",
       "  0.6990064272580264,\n",
       "  0.7044755025562007,\n",
       "  0.7114776805789201,\n",
       "  0.715967925559013,\n",
       "  0.7270770677207699,\n",
       "  0.7388009325753223,\n",
       "  0.7538003427000061,\n",
       "  0.7597293485250596,\n",
       "  0.7629577208889621,\n",
       "  0.7574178897531059,\n",
       "  0.7753670644110627,\n",
       "  0.7796361814468029,\n",
       "  0.783930360511744,\n",
       "  0.7840807232185315,\n",
       "  0.7879017052894226,\n",
       "  0.7931319659059498,\n",
       "  0.792728050407131,\n",
       "  0.7370334336889669,\n",
       "  0.7801786657668586,\n",
       "  0.7833554433253768,\n",
       "  0.7965740905427182,\n",
       "  0.7974408874359044,\n",
       "  0.8006191405599653,\n",
       "  0.8028686829273751,\n",
       "  0.8076154258996433,\n",
       "  0.8068267600885982,\n",
       "  0.8087637827983899,\n",
       "  0.8099622612250035,\n",
       "  0.812805885385459,\n",
       "  0.8122221236521642,\n",
       "  0.8139807785715062,\n",
       "  0.8158662085214294,\n",
       "  0.8165059863371742,\n",
       "  0.8198065919811148,\n",
       "  0.8131744225805847,\n",
       "  0.8217819442627557,\n",
       "  0.8195309259080473,\n",
       "  0.8243543250611793,\n",
       "  0.825086975949603,\n",
       "  0.8279586042342261,\n",
       "  0.8239946351543941]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_categorical_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-7c0f9533fb73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_categorical_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'categorical_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_categorical_accuracy'"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['val_acc'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Validation', 'Training'], loc='upper left')\n",
    "plt.savefig('Accuracy_MF_bilBF.png',dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
